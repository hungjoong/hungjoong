{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10 Minutes to Pandas (https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.htm)\n",
    "1. Object Creation (객체 생성)\n",
    "1. Viewing Data (데이터 확인하기)\n",
    "1. Selection (선택)\n",
    "1. Missing Data (결측치)\n",
    "1. Operation (연산)\n",
    "1. Merge (병합)\n",
    "1. Grouping (그룹화)\n",
    "1. Reshaping (변형)\n",
    "1. Time Series (시계열)\n",
    "1. Categoricals (범주화)\n",
    "1. Plotting (그래프)\n",
    "1. Getting Data In / Out (데이터 입 / 출력)\n",
    "1. Gotchas (잡았다!)\n",
    "\n",
    ">pandas 를 사용하기 위해서 다음과 같이 모듈을 임포트(import) 합니다. 임포트를 할 때에는 pandas 라는 네임스페이스를 그대로 사용해도 되지만 간결성을 위해 pd 라는 축약된 이름을 관례적으로 많이 사용합니다. 본 실습을 진행하기 위해 pandas 외에도 배열 구조나 랜덤 값 생성 등의 기능을 활용하기 위한 numpy 와 그래프를 그리기 위한 matplotlib 패키지들도 함께 import 해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Object Creation (객체 생성)\n",
    ">데이터 오브젝트는 ‘데이터를 담고 있는 그릇’이라고 생각하시면 쉬운데요. 여러분이 pandas 에서 자주 사용하시게 될 데이터 오브젝트는 Series 와 DataFrame 이 있습니다. 이 두 종류의 데이터 오브젝트를 잘 이해하고 사용하는 것이 pandas 의 전부라고 해도 과언이 아닐 정도로 중요합니다. 그렇다면 이 두 종류의 ‘그릇’의 차이점은 무엇일까요? 바로 데이터를 담는 그릇의 ‘형태’가 다른데요. 쉽게 말하자면 Series 는 1차원 배열로, DataFrame 은 2차원 배열로 데이터를 담고 있다고 생각하시면 됩니다. 이번 섹션에서는 Series 와 DataFrame 이라는 데이터 오브젝트를 만들어 보는 실습을 해 보겠습니다.\n",
    "\n",
    "![ ](image\\fig0.png \"Optional title\")\n",
    "\n",
    ">Pandas 의 중요한 데이터 오브젝트 중 하나인 Series는 기본적으로 아래와 같이 값의 리스트를 넘겨주어 만들 수 있습니다. 또한 값이 위치하고 있는 정보인 인덱스(index)가 Series 에 같이 저장되게 되는데요. 따로 전달해주지 않는 한 기본적으로 0부터 시작하여 1씩 증가하는 정수 인덱스가 사용됨을 알 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas는 값을 가지고 있는 리스트를 통해 Series를 만들고, 정수로 만들어진 인덱스를 기본값으로 불러올 것입니다.\n",
    "s = pd.Series([1,3,5,np.nan,6,8])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">또 다른 데이터 오브젝트인 DataFrame은 여러 형태의 데이터를 받아 생성할 수 있는데요. 그 중 한 방법으로 아래와 같이 numpy array 를 받아 생성이 가능합니다. 앞서 설명드린 것처럼 DataFrame 은 2차원 배열의 형태를 띄고 있습니다. 따라서 우리가 자주 보는 표 형태와 같이 두 가지의 기준에 따라 데이터를 담고 있습니다. 아래의 예제에서는 첫번째 기준은 날짜, 두번째 기준은 장소(A, B, C, D 라는 네 곳의 위치)1에 따라 측정된 어떤 값들이 담겨 있다고 생각하면 쉬울 것 같습니다. DataFrame 을 만들기 위해서는 pd.DataFrame() 라는 클래스 생성자를 사용하며, 행에 해당하는 기준(첫번째 기준)인 인덱스를 index 라는 인수로 전달하며, 열에 해당하는 기준(두번째 기준)인 컬럼을 columns 이라는 인수로 전달합니다. 여기에서는 인덱스로 pd.date_range() 를 사용하여 날짜 값들을 만들어 전달해 주었고, 컬럼의 이름은 A, B, C, D 라는 이름이 담긴 리스트로 넣어보았습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime 인덱스와 레이블이 있는 열을 가지고 있는 numpy 배열을 전달하여 데이터프레임을 만듭니다.\n",
    "dates = pd.date_range('20130101', periods=6)\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">DataFrame 을 생성하는 또 다른 방법으로 아래와 같이 여러 종류의 자료들이 담긴 딕셔너리(dict)를 넣어주어 만들 수 있습니다. 이 때에는 dict 의 key 값이 열을 정의하는 컬럼이 되며, 행을 정의하는 인덱스는 자동으로 0부터 시작하여 1씩 증가하는 정수 인덱스가 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series와 같은 것으로 변환될 수 있는 객체들의 dict로 구성된 데이터프레임을 만듭니다.\n",
    "df2 = pd.DataFrame({'A' : 1.,\n",
    "                    'B' : pd.Timestamp('20130102'),\n",
    "                    'C' : pd.Series(1,index=list(range(4)),dtype='float32'),\n",
    "                    'D' : np.array([3] * 4,dtype='int32'),\n",
    "                    'E' : pd.Categorical([\"test\",\"train\",\"test\",\"train\"]),\n",
    "                    'F' : 'foo' })\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">DataFrame 의 컬럼들은 각기 특별한 자료형을 갖고 있을 수 있습니다. 이는 DataFrame 내에 있는 dtypes 라는 속성을 통해 확인 가능합니다. 파이썬의 기본적인 소수점은 float64 로 잡히고, 기본적은 문자열은 str 이 아니라 object 라는 자료형으로 나타납니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 결과물의 열은 다양한 데이터 타입 (dtypes)으로 구성됩니다.\n",
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Jupyter 를 사용하시는 분이라면 df2.<TAB>(‘df2.’까지 입력하고 탭을 누름)을 통해 다음과 같이 dtypes 외에도 다른 속성들이 무엇이 있는지 확인할 수 있습니다.  \n",
    "IPython을 이용하고 계시다면 (공용 속성을 포함한) 열 이름에 대한 Tap 자동완성 기능이 자동으로 활성화 됩니다.\n",
    "\n",
    "```\n",
    "    df2.<TAB>\n",
    "    df2.A                  df2.bool\n",
    "    df2.abs                df2.boxplot\n",
    "    df2.add                df2.C\n",
    "    df2.add_prefix         df2.clip\n",
    "    df2.add_suffix         df2.clip_lower\n",
    "    df2.align              df2.clip_upper\n",
    "    df2.all                df2.columns\n",
    "    df2.any                df2.combine\n",
    "    df2.append             df2.combine_first\n",
    "    df2.apply              df2.compound\n",
    "    df2.applymap           df2.consolidate\n",
    "    df2.as_blocks          df2.convert_objects\n",
    "    df2.asfreq             df2.copy\n",
    "    df2.as_matrix          df2.corr\n",
    "    df2.astype             df2.corrwith\n",
    "    df2.at                 df2.count\n",
    "    df2.at_time            df2.cov\n",
    "    df2.axes               df2.cummax\n",
    "    df2.B                  df2.cummin\n",
    "    df2.between_time       df2.cumprod\n",
    "    df2.bfill              df2.cumsum\n",
    "    df2.blocks             df2.D\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">보다시피 컬럼 A, B, C, D 가 자동적으로 생성되어 나타나는 것을 확인할 수 있습니다. 나머지 속성들은 간결성을 위해 생략하였기 때문에 E 도 뒤에 있을 것입니다.  \n",
    "Ipython 을 사용하지 않는 분이라면, python 의 빌트인 함수 dir을 통해 다음과 같이 오브젝트가 갖고 있는 속성 및 메소드들을 모두 확인 가능합니다. (약 400 개가 넘는 항목입니다. 엄청 많습니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">이 외에도 pandas 에서 제공하는 자료 구조들이 무엇이 있는지 알아보시려면 pandas 공식 문서에 있는 Intro to data structures 을 참고하시면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. 데이터 확인하기 (Viewing Data)\n",
    "이 부분에 대해 더 자세히 알고 싶으시면 Essential basic functionality 을 참고해주세요.\n",
    "\n",
    ">DataFrame 에 들어있는 자료들을 확인하기 위해 맨 앞이나 뒤의 자료들 몇 개를 알아보고 싶다면 다음과 같이 .head()와 .tail() 메소드를 사용하면 됩니다. 기본적으로 상위 또는 하위 5 개의 자료를 보여주는데, 더 적게 혹은 많이 보고 싶다면 메소드의 인자로 보고싶은 데이터의 개수를 숫자를 넣어주면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임의 가장 윗 줄과 마지막 줄을 확인하고 싶을 때에 사용하는 방법은 다음과 같습니다.\n",
    "df.head()   # 위에서 5줄을 불러옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(3)  # 끝에서 마지막 3줄을 불러옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()  # 끝에서 마지막 5줄 불러옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">DataFrame의 인덱스를 보려면 .index 속성을, 컬럼을 보려면 .columns 속성을, 안에 들어있는 numpy 데이터를 보려면 .values 속성을 통해 확인하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 (index), 열 (column) 그리고 numpy 데이터에 대한 세부 정보를 봅니다.\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">.describe() 메소드는 생성했던 DataFrame 의 간단한 통계 정보를 보여줍니다. 컬럼별로 데이터의 개수(count), 데이터의 평균값(mean), 표준 편차(std), 최솟값(min), 4분위수(25%, 50%, 75%), 그리고 최댓값(max)들의 정보를 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe()는 데이터의 대략적인 통계적 정보 요약을 보여줍니다.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">.T 속성은 DataFrame 에서 index 와 column 을 바꾼 형태의 DataFrame 입니다. pandas.DataFrame.T 에는 .T를 ‘Transpose index and columns’와 같이 설명해 놓고 있어서 index 와 column 을 바꾼 후 리턴값으로 돌려주는 메소드로 착각할 수 있습니다. 따라서 .T()로 호출하는 경우가 있으실 텐데, 그렇게 해보니 에러가 나는군요. 메소드가 아니라 미리 계산되어 저장되어 있는 ‘속성’이라는 점을 다시 강조합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 전치합니다. (열과 행을 바꾼 형태의 데이터프레임입니다)\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .T는 속성임을 알아두세요. 다음과 같이 메소드로 호출한다면 에러를 냅니다.\n",
    "df.T()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">그리고 .sort_index() 라는 메소드로 행과 열 이름을 정렬하여 나타낼 수도 있습니다. 정렬할 대상 축을 결정할 때에는 axis 를 이용합니다. axis=0 라고 써주면 인덱스를 기준으로 정렬하며(기본값), axis=1 라고 써주면 컬럼을 기준으로 정렬합니다. 정렬의 방향에 대한 파라미터는 ascending 를 이용합니다. ascending=True 는 오름차순 정렬을 하겠다는 것이고(기본값), ascending=False 는 내림차순 정렬을 하겠다는 의미입니다. 다음은 컬럼에 대하여 내림차순 정렬을 하는 예제입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 축 별로 정렬합니다.\n",
    "df.sort_index(axis=1, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">또한 DataFrame 내부에 있는 값으로 정렬할 수도 있습니다. 다음은 B 컬럼에 대해 정렬한 결과를 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 값 별로 정렬합니다.\n",
    "df.sort_values(by='B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. 데이터 선택하기 (Selection)\n",
    ">선택과 설정을 위한 Python / Numpy의 표준화된 표현들이 직관적이며, 코드 작성을 위한 양방향 작업에 유용하지만 우리는 Pandas에 최적화된 데이터 접근 방법인 .at, .iat, .loc 및 .iloc 을 추천합니다.  \n",
    "데이터프레임 자체가 갖고 있는 [ ] 슬라이싱 기능을 이용하는 방법입니다. 특정 ‘컬럼’의 값들만 가져오고 싶다면 df['A']와 같은 형태로 입력합니다. 이는 df.A와 동일합니다. 리턴되는 값은 Series 의 자료구조를 갖고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting (데이터 얻기)\n",
    "df['A'] # A라는 이름을 가진 컬럼의 데이터만 갖고옵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">여러분의 이해를 돕기 위해 그림으로 다시 나타내면 다음과 같습니다. (앞으로 나오는 예제들도 그림으로 한번 더 설명하겠습니다.)\n",
    "\n",
    "![ ](image\\fig1.png \"Optional title\")\n",
    "\n",
    ">특정 ‘행 범위’를 가져오고 싶다면 다음과 같이 리스트를 슬라이싱 할 때와 같이 [ ]를 이용할 수 있습니다. df[0:3] 라고 하면 0, 1, 2번째 행을 가져옵니다(데이터프레임의 첫번째 행을 0번째 행이라고 가정). [0:3] 이라고 입력했지만 3번째 행을 가져오지 않음에 유의합니다. 또 다른 방법으로 df['20130102':'20130104'] 인덱스명을 직접 넣어서 해당하는 ‘행 범위’를 가져올 수도 있습니다. 이 때에는 숫자를 이용하여 슬라이싱 할 때와 달리 처음과 끝의 행이 모두 포함된 결과를 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행을 분할하는 [ ]를 통해 선택합니다.\n",
    "df[0:3] # 맨 처음 3개의 행을 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['20130102':'20130104']   # 인덱스명에 해당하는 값들을 가져옵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ ](image\\fig2.png \"Optional title\")\n",
    "\n",
    ">여기서 제가 왜 특정 ‘행’이 아니라 ‘행 범위’라고 강조하였는지를 설명드리겠습니다. 만약 특정 행 하나를 가져오고 싶은 경우에 df['20130102'] 라고 하면 KeyError 가 발생합니다. 왜일까요? 이 때에는 ‘20130102’라는 이름의 ‘인덱스’가 아니라 ‘컬럼’을 갖고 있는지 찾게 됩니다. 따라서 현재 데이터프레임에는 없으므로 키 값이 없다는 에러를 출력하게 되는 것입니다. 특정 ‘행 하나’를 선택하고 싶을 때에는 df['20130102':'20130102']와 같이 입력하면 됩니다. 다시 정리하자면, 데이터프레임 자체가 갖고 있는 슬라이싱은 df[컬럼명], df[시작인덱스:끝인덱스+1], df[시작인덱스명:끝인덱스명] 의 형태로 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 이름을 이용하여 선택하기: .loc\n",
    "라벨의 이름을 이용하여 선택할 수 있는 .loc를 이용할 수도 있습니다.\n",
    "\n",
    ">첫 번째 인덱스의 값인 ‘2013-01-01’에 해당하는 모든 컬럼의 값 가져오기. df.loc[dates[0]] 외에도 df.loc['20130101'] 또는 df.loc['2013-01-01'] 처럼 날짜를 직접 입력해도 잘 작동합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection by Label (Label 을 통한 선택)\n",
    "df.loc[dates[0]]    # 라벨을 사용하여 횡단면을 얻습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ ](image\\fig3.png \"Optional title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨을 사용하여 여러 축 (의 데이터)을 얻습니다.\n",
    "df.loc[:,['A','B']] # 컬럼 ‘A’와 컬럼 ‘B’에 대한 모든 값 가져오기."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ ](image\\fig4.png \"Optional title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 양쪽 종단점을 포함한 라벨 슬라이싱을 봅니다.\n",
    "# 인덱스 ‘2013-01-02’부터 ‘2013-01-04’까지의 컬럼 ‘A’와 컬럼 ‘B’의 값 가져오기.\n",
    "df.loc['20130102':'20130104', ['A','B']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ ](image\\fig5.png \"Optional title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반환되는 객체의 차원를 줄입니다.\n",
    "df.loc['20130101',['A','B']]    # 특정 인덱스 값의 컬럼 ‘A’, ‘B’ 값을 가져오기."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ ](image\\fig6.png \"Optional title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">특정 인덱스 값과 특정 컬럼에 있는 값 가져오기. 이는 .at을 이용할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스칼라 값을 얻습니다.\n",
    "df.loc[dates[0],'A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스칼라 값을 더 빠르게 구하는 방법입니다 (앞선 메소드와 동일합니다).\n",
    "df.at[dates[0],'A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ ](image\\fig7.png \"Optional title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 위치를 이용하여 선택하기: .iloc\n",
    ">다음과 같이 위치를 나타내는 인덱스 번호를 이용하여 데이터를 선택할 수 있습니다. 여기서 인덱스 번호는 python 에서 사용하는 인덱스와 같은 개념으로 이해하시면 됩니다. 인덱스 번호는 0 부터 시작하므로, 첫 번째 데이터는 인덱스 번호가 0 이고, 두 번째 데이터는 인덱스 번호가 1 이라는 뜻입니다. 아래는 인덱스 번호 3 (네 번째 행)을 선택하는 예제입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 넘겨받은 정수의 위치를 기준으로 선택합니다.\n",
    "df.iloc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ ](image\\fig8.png \"Optional title\")\n",
    "\n",
    ">인덱스 번호로 행 뿐만 아니라 열도 선택할 수 있습니다. 또한 numpy 나 python 의 슬라이싱 기능과 비슷하게 사용할 수 있습니다. 아래는 행과 열의 인덱스를 기준으로 이용하여 데이터를 선택하는 예제입니다. 행의 인덱스는 3:5로 네 번째 행과 다섯 번째 행을 선택하며, 열의 인덱스는 0:2로 첫 번째 열과 두 번째 열을 선택합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수로 표기된 슬라이스들을 통해, numpy / python과 유사하게 작동합니다.\n",
    "df.iloc[3:5,0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ ](image\\fig9.png \"Optional title\")\n",
    "\n",
    ">또한 행과 열의 인덱스를 리스트로 넘겨줄 수도 있습니다. 다음은 두 번째, 세 번째, 다섯 번째 행과, 첫 번째와 세 번째 열을 선택하는 예제입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수로 표기된 위치값의 리스트들을 통해, numpy / python의 스타일과 유사해집니다.\n",
    "df.iloc[[1,2,4],[0,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ ](image\\fig10.png \"Optional title\")\n",
    ">명시적으로 행이나 열 선택 인자에 : 슬라이스를 전달하면 다음과 같이 행 또는 열 전체를 가져올 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1:3,:]  # 명시적으로 행을 나누고자 하는 경우입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,1:3]  # 명시적으로 열을 나누고자 하는 경우입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ ](image\\fig11.png \"Optional title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "값 하나를 선택하기 위해서는 특정 행과 열을 지정하는 방식으로 하면 됩니다. 아래의 두 방법 모두 동일한 방법입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 명시적으로 (특정한) 값을 얻고자 하는 경우입니다.\n",
    "df.iloc[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스칼라 값을 빠르게 얻는 방법입니다 (위의 방식과 동일합니다).\n",
    "df.iat[1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ ](image\\fig12.png \"Optional title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 조건을 이용하여 선택하기\n",
    ">특정한 열의 값들을 기준으로 조건을 만들어 해당 조건에 만족하는 행들만 선택할 수 있는 방법이 있습니다. 다음은 A라는 열에 들어있는 값이 양수인 경우에 해당하는 행들을 선택하는 예제입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean Indexing\n",
    "df[df.A > 0]    # 데이터를 선택하기 위해 단일 열의 값을 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ ](image\\fig13.png \"Optional title\")\n",
    "\n",
    ">또한 각 값을 기준으로 조건을 만들 수도 있습니다. 이 때에는 행이 선택되는 것이 아니라 데이터 프레임의 전체 모양은 유지된 채로 조건에 맞는 값들만 그대로 보여지고 나머지 값들은 추후에 배울 결측치(missing value)로 나타나게 됩니다. 다음은 값이 양수인 것들만 보여지고 나머지 값들(0 혹은 음수)은 NaN 으로 보여지는 예제입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean 조건을 충족하는 데이터프레임에서 값을 선택합니다.\n",
    "df[df > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ ](image\\fig14.png \"Optional title\")\n",
    "\n",
    ">또한 필터링을 해야 하는 경우에 사용할 수 있는 isin()이라는 메소드도 제공합니다. 다음과 같이 새로운 열 하나를 추가한 후 새롭게 추가된 열에 들어있는 값을 기준으로 행을 선택할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필터링을 위한 메소드 isin()을 사용합니다.\n",
    "df2 = df.copy()\n",
    "df2['E'] = ['one', 'one', 'two', 'three', 'four', 'three']\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2['E'].isin(['two','four'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ ](image\\fig15.png \"Optional title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 데이터 변경하기\n",
    ">우리가 선택했던 데이터 프레임의 특정 값들을 다른 값으로 변경할 수 있습니다. 이에 대한 방법을 알아봅니다.  \n",
    "기존 데이터 프레임에 새로운 열을 추가하고 싶을 때는 다음과 같이 같은 인덱스를 가진 시리즈 하나를 데이터 프레임의 열 하나를 지정하여 넣어 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting (설정)\n",
    "# 새 열을 설정하면 데이터가 인덱스 별로 자동 정렬됩니다.\n",
    "s1 = pd.Series([1,2,3,4,5,6], index=pd.date_range('20130102', periods=6))\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['F'] = s1\n",
    "df.at[dates[0],'A'] = 0     # 데이터 프레임의 특정 값 하나를 선택하여 다른 값으로 바꿀 수 있습니다.\n",
    "df.iat[0,1] = 0             # 앞서 배운 값의 위치(인덱스 번호)를 이용한 변경도 가능합니다.\n",
    "df.loc[:,'D'] = np.array([5] * len(df))     # Numpy 배열을 사용한 할당에 의해 값을 설정합니다.\n",
    "# 여러 값을 한꺼번에 바꾸고 싶을 때는 데이터의 크기만 잘 맞춰 주면 됩니다. 다음은 NumPy array를 이용한 방법입니다.\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ ](image\\fig16.png \"Optional title\")\n",
    "\n",
    ">앞서 배운 조건을 이용한 데이터 선택 방법을 이용하여 다음과 같이 특정 조건에 만족하는 값들만 변경할 수도 있습니다. 다음은 양수의 값을 가지는 값들에 한해서 음수로 바꿔주는 예제입니다. 결국에는 0 또는 음수만을 가지는 데이터 프레임을 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where 연산을 설정합니다.\n",
    "df2 = df.copy()\n",
    "df2[df2 > 0] = -df2\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. 결측치 (Missing Data)\n",
    ">여러가지 이유로 우리는 데이터를 전부 다 측정하지 못하는 경우가 종종 발생합니다. 이처럼 측정되지 못하여 비어있는 데이터를 ‘결측치’라고 합니다. pandas 에서는 결측치를 np.nan 으로 나타냅니다. pandas 에서는 결측치를 기본적으로 연산에서 제외시키고 있습니다.  \n",
    "Working with missing data 항목을 참고하기 바랍니다.  \n",
    "재인덱싱(reindex)은 해당 축에 대하여 인덱스를 변경/추가/삭제를 하게됩니다. 이는 복사된 데이터프레임을 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + ['E'])\n",
    "df1.loc[dates[0]:dates[1],'E'] = 1\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">결측치가 하나라도 존재하는 행들을 버리고 싶을 때는 dropna() 메소드를 이용합니다. 결과적으로 결측치가 하나도 없는 두번째 행만 남고 나머지 행들은 사라졌습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dropna(how='any')   # 결측치를 가지고 있는 행들을 지웁니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">만약 결측치가 있는 부분을 다른 값으로 채우고 싶다면 fillna() 메소드를 이용하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.fillna(value=5) # 결측치를 채워 넣습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">그리고 해당 값이 결측치인지 아닌지의 여부를 알고싶다면 isna() 메소드를 이용하면 됩니다. 결측치이면 True, 값이 있다면 False 로 나타납니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nan인 값에 boolean을 통한 표식을 얻습니다.\n",
    "# 데이터프레임의 모든 값이 boolean 형태로 표시되도록 하며, nan인 값에만 True가 표시되게 하는 함수입니다.\n",
    "pd.isna(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. 연산 (Operations)\n",
    "통계적 지표들 (Stats)\n",
    "\n",
    ">평균 구하기. 일반적으로 결측치는 제외하고 연산을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats (통계)\n",
    "# 일반적으로 결측치를 제외한 후 연산됩니다.\n",
    "# 기술통계를 수행합니다.\n",
    "\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">다른 축에 대해서 평균 구하기. mean() 함수의 인자로 1을 주게 되면 컬럼이 아닌 인덱스를 기준으로 연산을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다른 축에서 동일한 연산을 수행합니다.\n",
    "df.mean(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">서로 차원이 달라 인덱스를 맞추어야 하는 두 오브젝트 간의 연산의 예제입니다. pandas 는 맞추어야 할 축만 지정해 준다면 자동으로 해당 축을 기준으로 맞추어 연산을 수행합니다. 아래는 인덱스를 기준으로 연산이 수행되고 있습니다. 기존 데이터 프레임의 인덱스가 2013-01-03, 04, 05 인 모든 컬럼에 해당하는 값에 각각 1.0, 3.0, 5.0 를 빼준 값이 결과로 나옵니다. 또한 결측치가 존재하는 경우에는 계산이 불가능 하므로 NaN 으로 표시된다는 것도 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정렬이 필요하며, 차원이 다른 객체로 연산해보겠습니다. 또한, pandas는 지정된 차원을 따라 자동으로 브로드 캐스팅됩니다.\n",
    "# broadcast란 numpy에서 유래한 용어로, n차원이나 스칼라 값으로 연산을 수행할 때 도출되는 결과의 규칙을 설명하는 것을 의미합니다.\n",
    "s = pd.Series([1,3,5,np.nan,6,8], index=dates).shift(2)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sub(s, axis='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 함수 적용하기 (Apply)\n",
    ">데이터프레임에 함수를 적용할 수 있습니다. 기존에 존재하는 함수를 사용하거나 사용자가 정의한 람다 함수를 사용할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply (적용)\n",
    "# 데이터에 함수를 적용합니다.\n",
    "df.apply(np.cumsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda x: x.max() - x.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 히스토그램 구하기 (Histogramming)\n",
    ">데이터의 값들의 빈도를 조사하여 히스토그램을 만들 수 있습니다. Histogramming and Discretization에서 더 많은 정보를 찾아보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramming (히스토그래밍)\n",
    "s = pd.Series(np.random.randint(0, 7, size=10))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 문자열 관련 메소드들 (String methods)\n",
    ">아래의 예제처럼 시리즈(Series)는 배열의 각 요소에 쉽게 적용이 가능하도록 str 이라는 속성에 문자열을 처리할 수 있는 여러가지의 메소드들을 갖추고 있습니다. 문자열 내에서의 패턴을 찾기 위한 작업들은 일반적으로 기본적으로 정규표현식을 사용하는 것에 유의합니다. (몇몇의 경우에는 항상 정규표현식을 사용합니다.) 더 많은 정보는 Vectorized String Methods 에서 찾아보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String Methods (문자열 메소드)\n",
    "# Series는 다음의 코드와 같이 문자열 처리 메소드 모음 (set)을 가지고 있습니다.\n",
    "# 이 모음은 배열의 각 요소를 쉽게 조작할 수 있도록 만들어주는 문자열의 속성에 포함되어 있습니다.\n",
    "# 문자열의 패턴 일치 확인은 기본적으로 정규 표현식을 사용하며, 몇몇 경우에는 항상 정규 표현식을 사용함에 유의하십시오.\n",
    "s = pd.Series(['A', 'B', 'C', 'Aaba', 'Baca', np.nan, 'CABA', 'dog', 'cat'])\n",
    "s.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. 합치기 (Merging)\n",
    ">다양한 정보를 담은 자료들이 있을 때 이들을 합쳐 새로운 자료를 만들어야 할 때가 있습니다. 이번에는 시리즈(Series) 또는 데이터프레임(DataFrame)을 어떻게 합치는지를 알아볼 것입니다. 같은 형태의 자료들을 이어 하나로 만들어주는 concat, 다른 형태의 자료들을 한 컬럼을 기준으로 합치는 merge, 기존 데이터 프레임에 하나의 행을 추가하는 append 의 사용법에 대해 알아봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concat\n",
    ">아래는 concat 을 이용하여 pandas 오브젝트들을 일렬로 잇는 예제입니다. 임의의 수를 담고있는 10 x 4 형태의 데이터 프레임을 만든 후 세 부분으로 쪼개었다가 pandas 에 있는 concat 메소드를 이용하여 원래대로 다시 합칠 수 있다는 것을 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat (연결)\n",
    "# 결합 (join) / 병합 (merge) 형태의 연산에 대한 인덱스, 관계 대수 기능을 위한 다양한 형태의 논리를 포함한 \n",
    "# Series, 데이터프레임, Panel 객체를 손쉽게 결합할 수 있도록 하는 다양한 기능을 pandas 에서 제공합니다.\n",
    "df = pd.DataFrame(np.random.randn(10, 4))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break it into pieces\n",
    "pieces = [df[:3], df[3:7], df[7:]]\n",
    "pd.concat(pieces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Join\n",
    ">데이터베이스에서 사용하는 SQL 스타일의 합치기 기능입니다. merge 메소드를 통해 이루어집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join (결합)\n",
    "# SQL 방식으로 병합합니다. 데이터베이스 스타일 결합 부분을 참고하세요.\n",
    "\n",
    "left = pd.DataFrame({'key': ['foo', 'foo'], 'lval': [1, 2]})\n",
    "right = pd.DataFrame({'key': ['foo', 'foo'], 'rval': [4, 5]})\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left, right, on= 'key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.DataFrame({'key' : ['foo', 'bar'], 'lval' : [1, 2]})\n",
    "right = pd.DataFrame({'key': ['foo', 'bar'], 'rval': [4, 5]})\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left, right, on= 'key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">위의 예제와 아래의 예제는 key 값을 중복으로 가질 때와 그렇지 않을 때의 merge 메소드의 작동방식을 설명해줍니다. 위의 예제에서는 key 값으로 모두 ‘foo’ 라는 문자열을 가지고 있고, 아래의 예제에서는 key 값으로 ‘foo’ 또는 ‘bar’ 를 가지고 있습니다. 보통 key 로 사용하는 값은 중복일 경우가 잘 없지만, 만약에 중복된 값이 있을 때에는 모든 경우의 수를 만들어내는 작동방식을 보여주고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Append\n",
    ">데이터프레임의 맨 뒤에 행을 추가합니다. 아래의 예제는 4번째 행을 기존의 데이터프레임의 맨 뒤에 한번 더 추가하는 방법을 보여주고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append (추가)\n",
    "df = pd.DataFrame(np.random.randn(8, 4), columns=['A', 'B', 'C', 'D'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df.iloc[3]\n",
    "df.append(s, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. 묶기 (Grouping)\n",
    ">‘그룹화 (group by)’는 다음과 같은 처리를 하는 과정들을 지칭합니다.\n",
    "\n",
    "- 어떠한 기준을 바탕으로 데이터를 나누는 일 (splitting)\n",
    "- 각 그룹에 어떤 함수를 독립적으로 적용시키는 일 (applying)\n",
    "- 적용되어 나온 결과들을 통합하는 일 (combining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'A' : ['foo', 'bar', 'foo', 'bar', 'foo', 'bar', 'foo', 'foo'],\n",
    "        'B' : ['one', 'one', 'two', 'three', 'two', 'two', 'one', 'three'],\n",
    "        'C' : np.random.randn(8),\n",
    "        'D' : np.random.randn(8)\n",
    "    })\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">A 컬럼의 값을 기준으로 그룹을 묶고 각 그룹에 합계를 구하는 sum() 함수를 적용해 봅시다. 인덱스로는 A 컬럼이 되고, 합계를 구할 수 있는 C 와 D 컬럼에 있는 숫자들의 합계가 구해진 데이터프레임이 만들어집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성된 데이터프레임을 그룹화한 후 각 그룹에 sum() 함수를 적용합니다.\n",
    "df.groupby('A').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 열을 기준으로 그룹화하면 계층적 인덱스가 형성됩니다. 여기에도 sum 함수를 적용할 수 있습니다.\n",
    "df.groupby(['A','B']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">그룹을 묶을 때 여러 컬럼을 기준으로 이용할 수도 있습니다. 다음은 A 와 B 컬럼을 기준으로 묶어 계층 구조의 인덱스를 형성하고, 앞의 예제와 마찬가지로 합계를 다시 구해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. 변형하기 (Reshaping)\n",
    ">데이터 프레임을 다른 형태로 변형하는 방법들에 대해 알아봅니다. 자세한 내용은 Hierarchical Indexing 과 Reshaping 을 참고 바랍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stack\n",
    ">stack 메소드는 데이터 프레임의 컬럼들을 인덱스의 레벨로 만듭니다. 이를 ‘압축’ 한다고 표현합니다. 아래 예제를 보시면 df2 라는 데이터프레임은 A 와 B 컬럼을 갖고 있었지만 stack 메소드를 통해 A 와 B 라는 값을 가지는 인덱스 레벨이 하나 더 추가된 형태로 변형되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack (스택)\n",
    "tuples = list(zip(*[['bar', 'bar', 'baz', 'baz',\n",
    "                     'foo', 'foo', 'qux', 'qux'],\n",
    "                    ['one', 'two', 'one', 'two',\n",
    "                     'one', 'two', 'one', 'two']]))\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])\n",
    "df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=['A', 'B'])\n",
    "df2  =  df[:4]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack() 메소드는 데이터프레임 열들의 계층을 “압축”합니다.\n",
    "stacked = df2.stack()\n",
    "stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">stack 메소드를 통해 압축된 수준을 갖는 데이터프레임은 다시 unstack 메소드를 통해 원래대로 돌아올 수 있습니다. 여러번 unstack 메소드를 적용할 수 있지만 기본적으로 unstack 메소드는 stack 메소드를 통해 압축되었던 마지막 수준부터 풀어주는 기능을 갖습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# “Stack된” 데이터프레임 또는 (MultiIndex를 인덱스로 사용하는) Series인 경우, stack()의 역 연산은 unstack()이며, \n",
    "# 기본적으로 마지막 계층을 unstack합니다.\n",
    "stacked.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">그리고 아래와 같이 해제할 수준을 지정해 줄 수 있습니다. stack() 메소드의 인수로 0 을 입력하면 첫 번째 수준을 해제하므로 인덱스에서 first 수준이 해제되어 bar 와 baz 라는 컬럼이 생기게 되고, 1 을 입력하면 두 번째 수준인 second 를 해제하므로 one 과 two 라는 컬럼이 만들어진 데이터프레임을 얻을 수 있게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked.unstack(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked.unstack(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pivot Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot Tables (피봇 테이블)\n",
    "df = pd.DataFrame({'A' : ['one', 'one', 'two', 'three'] * 3,\n",
    "                   'B' : ['A', 'B', 'C'] * 4,\n",
    "                   'C' : ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'] * 2,\n",
    "                   'D' : np.random.randn(12),\n",
    "                   'E' : np.random.randn(12)})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">위와 같은 데이터 프레임의 형식을 피벗 테이블 기능을 이용하여 아래와 같이 쉽게 변형할 수 있습니다. 찾지 못한 값은 NaN 으로 표시됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 데이터로부터 피봇 테이블을 매우 쉽게 생성할 수 있습니다.\n",
    "pd.pivot_table(df, values='D', index=['A', 'B'], columns=['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. 시계열 데이터 다루기 (Time Series)\n",
    ">시계열 데이터에서 1초 마다 측정된 데이터를 5분 마다 측정된 데이터의 형태로 바꾸고 싶을 땐 어떻게 할까요? Pandas 는 이렇게 시계열 단위인 주기(frequency)를 다시 샘플링 할 수 있는 단순하고, 강력하며, 효과적인 기능을 가지고 있습니다. 이는 특히 금융 데이터를 다룰 때 매우 흔히 하는 연산입니다. (그렇다고 꼭 금융 데이터에 한정되어 있다는 뜻은 아닙니다.) Time series / date functionality 을 참고하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = pd.date_range('1/1/2012', periods=100, freq='S')\n",
    "ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)\n",
    "ts.resample('5Min').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간대를 표현합니다.\n",
    "rng = pd.date_range('3/6/2012 00:00', periods=5, freq='D')\n",
    "ts = pd.Series(np.random.randn(len(rng)), rng)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_utc = ts.tz_localize('UTC')\n",
    "ts_utc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다른 시간대로 변환합니다.\n",
    "ts_utc.tz_convert('US/Eastern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간 표현 ↔ 기간 표현으로 변환합니다.\n",
    "rng = pd.date_range('1/1/2012', periods=5, freq='M')\n",
    "ts = pd.Series(np.random.randn(len(rng)), index=rng)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = ts.to_period()\n",
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.to_timestamp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">기간과 특정시간 사이의 변환에 편리한 산술적 기능들을 사용할 수 있습니다. 뒤이어 나오는 예제는 11월을 끝으로 하는 4분기 체계에서 각 분기의 마지막 달에 9시간을 더한 시각을 시작으로 하는 체계로 바꾸는 것을 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기간 ↔ 시간 변환은 편리한 산술 기능들을 사용할 수 있도록 만들어줍니다. 다음 예제에서, \n",
    "# 우리는 11월에 끝나는 연말 결산의 분기별 빈도를 분기말 익월의 월말일 오전 9시로 변환합니다.\n",
    "\n",
    "prng = pd.period_range('1990Q1', '2000Q4', freq='Q-NOV')\n",
    "ts = pd.Series(np.random.randn(len(prng)), prng)\n",
    "ts.index = (prng.asfreq('M', 'e') + 1).asfreq('H', 's') + 9\n",
    "ts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. 범주형 데이터 다루기 (Categoricals)\n",
    ">Pandas는 데이터프레임 내에 범주형 데이터를 포함할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"id\":[1,2,3,4,5,6], \"raw_grade\":['a', 'b', 'b', 'a', 'a', 'e']})\n",
    "# 가공하지 않은 성적을 범주형 데이터로 변환합니다.\n",
    "df[\"grade\"] = df[\"raw_grade\"].astype(\"category\")\n",
    "df[\"grade\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">단순한 문자로 되어있는 raw grade 컬럼을 범주형으로 바꿀 수 있습니다.  \n",
    "범주들의 이름을 더욱 의미있는 것으로 바꾸어 줄 수 있습니다. (곧바로 Series.cat.categories 에 이름들을 할당하면 됩니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주에 더 의미 있는 이름을 붙여주세요 (Series.cat.categories로 할당하는 것이 적합합니다).\n",
    "df[\"grade\"].cat.categories = [\"very good\", \"good\", \"very bad\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">범주의 순서를 재정렬하는 동시에, 현재 갖고있지 않는 범주도 추가 가능합니다. (Series.cat 아래의 메소드들은 기본적으로 새로운 시리즈를 반환합니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주의 순서를 바꾸고 동시에 누락된 범주를 추가합니다 (Series.cat에 속하는 메소드는 기본적으로 새로운 Series를 반환합니다).\n",
    "df[\"grade\"] = df[\"grade\"].cat.set_categories([\"very bad\", \"bad\", \"medium\", \"good\", \"very good\"])\n",
    "df[\"grade\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">정렬은 범주 이름의 어휘적 순서가 아닌, 범주에 이미 매겨진 값의 순서대로 이루어집니다. (즉, 범주형 자료를 만들거나 범주들을 재정의할 때 이루어진 순서가 범주에 매겨진 값입니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정렬은 사전 순서가 아닌, 해당 범주에서 지정된 순서대로 배열합니다.\n",
    "# 131번에서 very bad, bad, medium, good, very good 의 순서로 기재되어 있기 때문에 정렬 결과도 해당 순서대로 배열됩니다.\n",
    "df.sort_values(by=\"grade\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">범주형 자료를 담고있는 컬럼을 그룹으로 묶고 각 범주에 해당하는 값의 빈도수를 출력합니다. 이렇게 하면 비어있는 범주가 무엇인지도 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주의 열을 기준으로 그룹화하면 빈 범주도 표시됩니다.\n",
    "df.groupby(\"grade\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. 그래프로 표현하기 (Plotting)\n",
    ">다음과 같은 시계열 데이터가 있을 때, 그래프 그리기는 다음과 같이 plot() 메소드 하나만으로 완성할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000))\n",
    "ts = ts.cumsum()\n",
    "ts.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">plot() 메소드는 여러 개의 열을 한 번에 그릴 수 있는 편리함도 제공하고 있다. 다음과 같이 A, B, C, D의 4개의 열에 해당하는 데이터를 legend 와 함께 표시할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임에서 plot() 메소드는 라벨이 존재하는 모든 열을 그릴 때 편리합니다.\n",
    "df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index,\n",
    "                  columns=['A', 'B', 'C', 'D'])  \n",
    "df = df.cumsum()\n",
    "plt.figure(); df.plot(); plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. 데이터 입/출력 (Getting Data In/Out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 파일에 씁니다.\n",
    "df.to_csv('foo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">CSV 형식으로 된 파일로부터 데이터 프레임의 형식으로 읽어오기. CSV 형식으로 부터 읽어올 때 주의할 점은 기존 행 인덱스를 인식하지 못하고 행 인덱스를 가지는 새로운 열이 추가로 잡힌다는 것입니다. 따라서 저장할 당시에는 4개였던 열의 개수가 5개가 되어있는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 파일을 읽습니다.\n",
    "pd.read_csv('foo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel\n",
    "# 엑셀 파일에 씁니다.\n",
    "df.to_excel('foo.xlsx', sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 엑셀 파일을 읽어옵니다.\n",
    "pd.read_excel('foo.xlsx', 'Sheet1', index_col=None, na_values=['NA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gotchas (잡았다!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pd.Series([False, True, False]):\n",
    "    print(\"I was true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이러한 경우에는 any(), all(), empty 등을 사용해서 무엇을 원하는지를 선택 (반영)해주어야 합니다.\n",
    "if pd.Series([False, True, False])is not None:\n",
    "      print(\"I was not None\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9efce205f64ad363cd9f14615485aca38ee4ef0915866e318aa83c8d0c93f6fc"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
