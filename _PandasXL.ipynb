{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dogRwtVff2Df"
   },
   "source": [
    "# [Python] Pandas 정리\n",
    "\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "\n",
    "- 주피터에서 보이는 행 늘리기\n",
    "\n",
    "        pd.set_option('max_rows', 500)\t\n",
    "\n",
    "- 주피터에서 보이는 열 늘리기\n",
    "\n",
    "        pd.set_option('max_columns', 500)\t\n",
    "\n",
    "\n",
    "- 데이터프레임 만들기\n",
    "\n",
    "        pd.DataFrame({'col':[data]})\n",
    "        pd.DataFrame([[20190103, 'Kim', 'H'],\n",
    "                      [20190222, 'Lee', 'W'],\n",
    "                      [20190531, 'Jeong', 'S']], columns = ['ID', 'name', 'class'])\n",
    "\n",
    "- 행 조회\n",
    "\n",
    "        df.head()   # 상위 n개 값만 보이기   \n",
    "        df.tail()   # 하위 n개 값만 보이기   \n",
    "        df.sample()   # 랜덤으로 n개 값만 보이기  \n",
    "\n",
    "- 데이터프레임의 열 이름 조회\n",
    "\n",
    "        df.columns\n",
    "\n",
    "- 데이터타입 조회\n",
    "\n",
    "        df.dtypes / df['col'].dtypes\t\n",
    "\n",
    "- 데이터타입 변경\n",
    "\n",
    "        df.astype({'col1':'int'})\n",
    "        df['col'].astype('type')\n",
    "\n",
    "- to_~\n",
    "\n",
    "        s.to_list()\n",
    "        s.to_frame()   # 데이터프레임으로 \n",
    "        pd.to_numeric(data)\n",
    "        pd.to_datetime(data)\n",
    "        s.to_timestamp()\n",
    "\n",
    "- 데이터프레임 정보\n",
    "\n",
    "        df.info()\n",
    "\n",
    "- 데이터프레임 형태\n",
    "\n",
    "        df.shape   # (행, 열)\n",
    "        df.ndim   # 행\n",
    "\n",
    "- 기술통계\n",
    "\n",
    "        df.describe(include = 'all')\n",
    "\n",
    "- 상관계수\n",
    "\n",
    "        data.corr()\n",
    "\n",
    "- 공분산\n",
    "\n",
    "        data.cov()\n",
    "\n",
    "- 누적~\n",
    "\n",
    "        data.cumsum()   # 누적합\n",
    "        data.cum**()   # **에 min, max, prod\n",
    "\n",
    "- 고유값(Unique)\n",
    "\n",
    "        df.unique()\n",
    "\n",
    "- 고유값의 갯수\n",
    "\n",
    "        data.nunique()\n",
    "\n",
    "- 데이터의 갯수\n",
    "\n",
    "        data.count()\n",
    "\n",
    "- 상위 n개 / 하위 n개\n",
    "\n",
    "        s.nlargest(n, keep = ) / s.nsmallest(n, keep = )\n",
    "\n",
    "\n",
    "- 복사\n",
    "\n",
    "        df.copy()\n",
    "\n",
    "- 값 선택하여 조회\n",
    "\n",
    "        df.loc[행, 열]\n",
    "        df.iloc['row', 'col']   # 인덱스\n",
    "        df.at[행, 'col']\n",
    "        df.iat[행, 열]   # 인덱스\n",
    "\n",
    "- 행/열 삭제\n",
    "\n",
    "        df.drop(['A', 'B'], axis=1)\n",
    "\n",
    "\n",
    "- 결측값이 있는지\n",
    "\n",
    "        data.isnull() / data.isna()\t\n",
    "\n",
    "- 결측값이 아닌 값\n",
    "\n",
    "        data.notnull() / data.notna()\n",
    "\n",
    "- 결측값이 있는 행 조회\n",
    "\n",
    "        df[df.isnull().any(axis=1)]\n",
    "\n",
    "- 결측값 채우기\n",
    "\n",
    "        df.fillna('값')\t\n",
    "\n",
    "- 결측값이 있는 행/열 제외\n",
    "\n",
    "        pd.dropna()\n",
    "\n",
    "\n",
    "- 데이터 가져오기\n",
    "\n",
    "        pd.read_csv('path/file_name.csv')\n",
    "        pd.read_excel('path/file_name.xlsx')  \n",
    "        pd.read_table('path/file_name.csv', sep='t')\n",
    "        pd.read_table('URL')\n",
    "        pd.read_json('URL')\n",
    "\n",
    "- 데이터 내보내기\n",
    "\n",
    "        pd.to_csv(df, 'path/file_name.csv', index = False)\n",
    "        pd.to_excel(df, 'path/file_name.xlsx', index = False, sheet_name = )\n",
    "\n",
    "- 인덱스 재정렬\n",
    "\n",
    "        df.reset_index(drop = )\t\n",
    "\n",
    "- 인덱스 순으로 정렬\n",
    "\n",
    "        df.sort_index(ascending = , inplace = )\t\n",
    "\n",
    "- col을 기준으로 데이터프레임 정렬\n",
    "\n",
    "        df.sort_values(by = ['col'], ascending = False)\t\n",
    "\n",
    "- 중복 제거\n",
    "\n",
    "        df.drop_duplicates(['col1', 'col2'], keep='last')\n",
    "\n",
    "- 데이터프레임 합치기\n",
    "\n",
    "        pd.concat([df1, df2], axis = 0)   # axis = 0(행)/1(열)\n",
    "        pd.merge(df1, df2, on = '기준', how = '방식')\n",
    "\n",
    "- GroupBy\n",
    "\n",
    "        df.groupby(['col'], axis = 1, as_index = ).exp()\t\n",
    "\n",
    "- 피봇테이블\n",
    "\n",
    "        pd.pivot_table(df, values =, index =, columns =, values =, aggfunc =)\n",
    "\n",
    "- melt : 열 이름을 기준으로 값 생성\n",
    "\n",
    "        pd.melt(df, id_vars = ['A'], value_vars = ['B', 'C']) \n",
    "\n",
    "- 속해있는 값 찾기 / 특정 값을 포함하는지\n",
    "\n",
    "        df.isin([리스트])\n",
    "        df.isin({'col' : [리스트]})\n",
    "        df['col'].isin([리스트])\n",
    "\n",
    "- 문자를 포함하는지\n",
    "\n",
    "        df.contains('문자') / df['col'].str.contains('문자')\n",
    "\n",
    "- 문자 변경\n",
    "\n",
    "        df.replace('Before', 'After') / df['col'].str.contains('Before', 'After')\n",
    "\n",
    "- 데이터 옮기기\n",
    "\n",
    "        df.shift(periods=n, axis = 0, fill_value=0)\n",
    "\n",
    "- n번째 값과의 차이\n",
    "\n",
    "        s.diff(periods=-n)\n",
    "\n",
    "- 특정 기간의 시간 데이터 생성\n",
    "\n",
    "        pd.date_range(start = 'yyyy-mm-dd', end = 'yyyy-mm-dd', periods = 3, freq = 'M')\n",
    "\n",
    "- One-Hot Encoding\n",
    "\n",
    "        pd.get_dummies(data)\n",
    "\n",
    "- 조건에 따른 값 반환\n",
    "\n",
    "        np.where(조건, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1629470128594,
     "user": {
      "displayName": "김흥중",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkqqoR6vik2TRupwbatmAoSf6l_wMwMfaJy0-WvQ=s64",
      "userId": "03510055984323851364"
     },
     "user_tz": -540
    },
    "id": "d9xC0vlctoDr"
   },
   "outputs": [],
   "source": [
    "# 판다스 라이브러리를 불러오기\n",
    "# 판다스 라이브러리를 불러와서 pd라는 축약어로 지정합니다. 매번 pandas라는 전체 단어를 타이핑하는 것이 번거로우니 pd라는 짧은 단어 사용하기 위함입니다.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "executionInfo": {
     "elapsed": 737,
     "status": "ok",
     "timestamp": 1629470131475,
     "user": {
      "displayName": "김흥중",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkqqoR6vik2TRupwbatmAoSf6l_wMwMfaJy0-WvQ=s64",
      "userId": "03510055984323851364"
     },
     "user_tz": -540
    },
    "id": "dEjB1bVvt9N9",
    "outputId": "7545b46e-5f8a-4ced-dbdf-e68525d5b320"
   },
   "outputs": [],
   "source": [
    "# 판다스에서 엑셀 파일(xlsx)을 읽으려면 pd.read_excel()를 사용해야 합니다. \n",
    "sales = pd.read_excel('SupermarketSales.xlsx') # SupermarketSales.xlsx라는 엑셀 파일을 읽어와 그 결과를 sales라는 이름의 변수에 저장\n",
    "sales\n",
    "# 이제 sales라는 변수를 입력하면 엑셀에서 보는 것과 유사하게 표 형식으로 읽어온 데이터를 화면에서 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3mlD_CKRvIst"
   },
   "source": [
    "## 엑셀과 판다스의 몇 가지 차이점\n",
    "\n",
    "- 엑셀은 행 번호가 1부터 시작하지만 판다스는 0부터 시작합니다.\n",
    "- 엑셀 파일에 값이 없는 데이터는 판다스에서 Nan(Null)로 표기됩니다.\n",
    "- 판다스에서 숫자는 기본적으로 모두 실수로 표현되기 때문에 소수점이 있습니다. 설정을 바꿔서 없앨 수 있습니다.\n",
    "\n",
    "판다스에서는 위와 같은 테이블 형식의 데이터를 데이터프레임이라는 자료구조로 저장합니다. 데이터프레임을 엑셀의 시트와 유사한 개념으로 생각하시면 됩니다. 그리고 이 데이터프레임에서는 행 번호가 있는 부분을 Index라 합니다. (정확히는 행 번호가 아니라 행 데이터의 이름을 나타냅니다.) 또한 각 열 데이터 이름을 Column name이라 합니다.\n",
    "\n",
    "그림으로 간단히 보면 이렇습니다.\n",
    "![ ](image/DataFrame.png \"Optional title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1629470142359,
     "user": {
      "displayName": "김흥중",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkqqoR6vik2TRupwbatmAoSf6l_wMwMfaJy0-WvQ=s64",
      "userId": "03510055984323851364"
     },
     "user_tz": -540
    },
    "id": "dRcEk1MQuy36",
    "outputId": "f9ce509e-1d40-4615-e5d2-bf263dc41d8b"
   },
   "outputs": [],
   "source": [
    "# 이 sales 변수의 데이터 타입을 확인\n",
    "type(sales) # 데이터프레임인 것을 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bbnq9dkYwASq"
   },
   "source": [
    "## 데이터 정렬하기 pandas sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "executionInfo": {
     "elapsed": 296,
     "status": "ok",
     "timestamp": 1629470156035,
     "user": {
      "displayName": "김흥중",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkqqoR6vik2TRupwbatmAoSf6l_wMwMfaJy0-WvQ=s64",
      "userId": "03510055984323851364"
     },
     "user_tz": -540
    },
    "id": "SqYiWBnJwDAG",
    "outputId": "a3845d35-5ac0-4a4b-970d-202d2cafabdf"
   },
   "outputs": [],
   "source": [
    "# .sort_values() 메서드에 정렬할 기준이 되는 열 이름을 알려줍니다. 지점 이름을 기준으로 정렬해보겠습니다.\n",
    "sales = sales.sort_values('지점')\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "executionInfo": {
     "elapsed": 310,
     "status": "ok",
     "timestamp": 1629470163577,
     "user": {
      "displayName": "김흥중",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkqqoR6vik2TRupwbatmAoSf6l_wMwMfaJy0-WvQ=s64",
      "userId": "03510055984323851364"
     },
     "user_tz": -540
    },
    "id": "fIWmFjnlwVDI",
    "outputId": "1c4323f3-e923-4e0c-c7f1-f5f623f50553"
   },
   "outputs": [],
   "source": [
    "# 기본 정렬 방식은 오름차순입니다. 내림차순으로 정렬하기 위해서는 ascending 옵션을 추가하면 됩니다.\n",
    "sales = sales.sort_values('지점', ascending=False)\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1629470174451,
     "user": {
      "displayName": "김흥중",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjkqqoR6vik2TRupwbatmAoSf6l_wMwMfaJy0-WvQ=s64",
      "userId": "03510055984323851364"
     },
     "user_tz": -540
    },
    "id": "uV4-e22Ewa_V",
    "outputId": "6d3001ad-219b-4f9d-a3da-27ada96507b0"
   },
   "outputs": [],
   "source": [
    "# 정렬 기준이 되는 열을 추가하고 싶다면 by 옵션을 추가하면 됩니다. '지점'은 오름차순으로 '고객타입'은 내림차순으로 정렬해보겠습니다.\n",
    "sales = sales.sort_values(by=['지점', '고객타입'], ascending=[True, False])\n",
    "sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtQUYPZVwqbq"
   },
   "source": [
    "## 데이터 필터링하기, 비교 연산자 pandas filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMie379Zw3aZ"
   },
   "source": [
    "### 판다스에서 데이터를 필터링하는 방법은 세 가지 단계를 거칩니다.\n",
    "\n",
    "- 필터링할 열(컬럼)을 선택합니다.\n",
    "- 컬럼의 데이터와 조건을 비교합니다. 조건을 만족하는 경우에는 True, 아닌 경우에는 False 반환합니다.\n",
    "- 비교 결과를 이용해서 데이터프레임에서 데이터를 필터링합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hRTVjb7Xwji3"
   },
   "outputs": [],
   "source": [
    "# 지점 컬럼의 값이 A인 데이터를 필터링해보겠습니다.\n",
    "# 지점 컬럼의 값이 A와 같은지 비교합니다.\n",
    "condition_A = (sales['지점'] == 'A')\n",
    "# 데이터프레임에서 위의 조건을 만족하는 데이터만 필터링합니다\n",
    "sales_from_A = sales[condition_A]\n",
    "sales_from_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cdoU8EksxPJO"
   },
   "outputs": [],
   "source": [
    "condition_member = (sales['고객타입'] == '회원')\n",
    "sales_member = sales[condition_member]\n",
    "sales_member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p2MezJ5hxTvV"
   },
   "outputs": [],
   "source": [
    "condition_female = (sales['성별'] == '여성')\n",
    "sales_female = sales[condition_female]\n",
    "sales_female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MmZ1WfbhxWZ8"
   },
   "outputs": [],
   "source": [
    "# 다수의 조건을 동시에 만족하는 데이터 필터링하기\n",
    "# 컴퓨터에게 \"지점은 A이면서 고객타입은 회원인 성별 여성의 데이터를 필터링해줘\"라고 전달해보겠습니다.\n",
    "# 판다스에서 복수의 조건을 입력하는 방법은 &와 |를 이용하는 것입니다. &는 and를 |는 or을 의미합니다.\n",
    "sales_all_condition = sales[condition_A & condition_member & condition_female]\n",
    "sales_all_condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72R7K3evyAML"
   },
   "source": [
    "## 사칙연산하기 pandas arithmetic\n",
    "\n",
    "판다스에서 컬럼끼리 사칙연산을 하기 위해서는 원하는 컬럼을 선택한뒤 + - * / 계산을 하면됩니다. 그리고 계산 결과를 새컬럼명으로 저장합니다. 가상의 컬럼을 이용하여 예를 들면 다음과 같습니다.\n",
    "\n",
    "- 덧셈\n",
    "        sales['새컬럼명'] = sales['기존컬럼1'] + sales['기존컬럼2']\n",
    "- 뺄셈\n",
    "        sales['새컬럼명'] = sales['기존컬럼1'] - sales['기존컬럼2']\n",
    "- 나눗셈\n",
    "        sales['새컬럼명'] = sales['기존컬럼1'] / sales['기존컬럼2']\n",
    "- 곱셉\n",
    "        sales['새컬럼명'] = sales['기존컬럼1'] * sales['기존컬럼2']\n",
    "\n",
    "- 복잡한 연산도 가능합니다\n",
    "        sales['새컬럼명'] = (sales['기존컬럼1'] + sales['기존컬럼2']) / sales['기존컬럼3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4bqjKtD7yCCR"
   },
   "outputs": [],
   "source": [
    "# 매출원가 컬럼을 매출액 컬럼으로 나눕니다. 그리고 그 결과를 매출원가율이라는 이름의 새 컬럼으로 저장하여 출력합니다. 엑셀과 달리 판다스에서는 작업을 수행하면 모든 행의 결과가 한 번에 계산되어 나타납니다.\n",
    "sales['매출원가율'] = sales['매출원가'] / sales['매출액']\n",
    "sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4kb8HY71yzcG"
   },
   "source": [
    "## 데이터 합치기 pandas merge()\n",
    "데이터 정리 작업을 하다 보면 두 개의 서로 다른 시트 또는 테이블을 하나로 합쳐야 할 때가 있습니다. 이때 엑셀의 경우 vlookup을 사용하여 손쉽게 두 시트를 병합할 수 있습니다. 판다스에서는 데이터 병합 전용 메서드인 merge가 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BFVTPc0HyU8c"
   },
   "outputs": [],
   "source": [
    "# 판매 데이터에 제품군 담당 매니저의 이름을 넣어주려 합니다.\n",
    "# 새로운 엑셀 파일을 불러옵니다.\n",
    "# PrdManager.xlsx 파일을 읽어와 그 결과를 prd_manager라는 이름의 변수에 저장합니다.\n",
    "prd_manager = pd.read_excel('PrdManager.xlsx')\n",
    "# 결과를 출력합니다.\n",
    "prd_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QImOmRdCzfo5"
   },
   "source": [
    "###데이터를 하나로 합치기\n",
    "판다스에서 여러 개의 데이터 집합을 연결해서 하나로 만드는 가장 대표적인 방법은 merge() 메서드를 이용하는 것입니다. merge 함수에는 다음의 인수들이 들어갑니다.\n",
    "\n",
    "- 첫 번째 데이터프레임\n",
    "- 두 번째 데이터프레임\n",
    "- how = 'left' (왼쪽 데이터프레임을 기준으로 합친다는 의미입니다.)\n",
    "- on = 두 데이터프레임을 합치는 기준이 되는 컬럼의 이름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzaglz2Tza_v"
   },
   "outputs": [],
   "source": [
    "sales = pd.merge(sales, prd_manager, how='left', on='제품군')\n",
    "sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eG7cTuufzyE1"
   },
   "source": [
    "### merger 더 알아보기\n",
    "merge() 함수는 두 데이터프레임의 공통 컬럼 또는 인덱스를 기준으로 두 개의 데이터를 합칩니다. 이때 기준이 되는 컬럼을 키(key)라고 하며, 키를 기준으로 아래와 같이 네 가지 방법으로 연결할 수 있습니다.\n",
    "\n",
    "- Inner Join: 두 데이터프레임에서 키 값이 일치하는 데이터만 합칩니다. how 옵션에 inner를 집어넣으면 됩니다. \n",
    "- Outer Join: 두 데이터프레임의 모든 데이터를 합칩니다. how 옵션에 outer를 집어넣으면 됩니다. \n",
    "- Left Outer Join: 데이터프레임의 A를 기준으로 A의 키 값을 충족하는 B의 데이터만 합칩니다. how 옵션에 left를 집어넣으면 됩니다. \n",
    "- Right Outer Join: 데이터프레임의 B를 기준으로 B의 키 값을 충족하는 A의 데이터만 합칩니다. how 옵션에 right를 집어넣으면 됩니다.\n",
    "\n",
    "이를 그림으로 나타내면 아래와 같습니다. \n",
    "\n",
    "![ ](image/Merge.png \"Optional title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRn4bnal0WzV"
   },
   "source": [
    "## 피벗 테이블 만들기 pandas pivot_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cJFEUNi0zn9R"
   },
   "outputs": [],
   "source": [
    "# pd.pivot_table() 메서드를 사용해서 피벗 테이블을 만들 수 있습니다.\n",
    "# pd.pivot_table(data=데이터프레임의 이름, value=집계할 컬럼의 이름, index=피벗테이블의 행, columns=피벗테이블의 열, aggfunc=집계 방법)\n",
    "table = pd.pivot_table(sales, index='제품군', columns='날짜', values='매출액', aggfunc='sum')\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5UiV3zKI0mk8"
   },
   "outputs": [],
   "source": [
    "# 위의 코드에서 제품군별 날짜별 매출액에 피벗 테이블로 집계된 것을 볼 수 있습니다. 다만 날짜별로 집계가 되어서 테이블이 가로로 너무 길어졌습니다. 조금 더 깔끔하게 월별 집계를 해보겠습니다.\n",
    "# 월별 집계하기\n",
    "# 매개변수 columns에 날짜가 아닌 월을 전달하기 위해서는 월 컬럼이 필요합니다.\n",
    "sales['월'] = sales['날짜'].dt.strftime('%m')\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mp-4pBvd03uP"
   },
   "outputs": [],
   "source": [
    "# 월 컬럼을 이용해서 피벗 테이블을 새로 만들어보겠습니다.\n",
    "table = pd.pivot_table(sales, index='제품군', columns='월', values='매출액', aggfunc='sum')\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIyR1PzwbPZB"
   },
   "source": [
    "## 데이터프레임 중복 제거 :: drop_duplicates\n",
    "\n",
    "데이터프레임에서 중복되는 행을 제거하고 고유한 값만 남기고 싶을 때 Pandas의 drop_duplicates를 활용하면 된다.  \n",
    "df.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "executionInfo": {
     "elapsed": 383,
     "status": "ok",
     "timestamp": 1629260075974,
     "user": {
      "displayName": "김흥중",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgvOxCHkryGVlZI4L_etMcHh1YeD6_ld365TwI47yU=s64",
      "userId": "04380006385771757274"
     },
     "user_tz": -540
    },
    "id": "07nlButGbhSD",
    "outputId": "e4f34ed1-748a-4776-e794-170dfcd9defc"
   },
   "outputs": [],
   "source": [
    "# 중복이 있는 예시데이터를 생성하였다.\n",
    "\n",
    "df = pd.DataFrame({'Num':[1, 2, 1, 2, 2, 3], \n",
    "                   'Alphabet':['a', 'b', 'a', 'b', 'a', 'b']})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "executionInfo": {
     "elapsed": 415,
     "status": "ok",
     "timestamp": 1629259518889,
     "user": {
      "displayName": "김흥중",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgvOxCHkryGVlZI4L_etMcHh1YeD6_ld365TwI47yU=s64",
      "userId": "04380006385771757274"
     },
     "user_tz": -540
    },
    "id": "RE3Ril-wbmCz",
    "outputId": "e52dd49d-f39f-4435-efb6-337eaa706ad0"
   },
   "outputs": [],
   "source": [
    "# 중복제거\n",
    "\n",
    "df.drop_duplicates()\n",
    "\n",
    "# 아무것도 지정하지 않고 그냥 drop_duplicates를 할 경우 모든 열(column)을 기준으로 중복을 제거한다.\n",
    "# 예시데이터에서 ['Num', 'Alphabet']을 쌍으로 취급하여 중복을 제거하였기에 각 열에는 여전히 중복되는 데이터가 남아있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "executionInfo": {
     "elapsed": 393,
     "status": "ok",
     "timestamp": 1629259803580,
     "user": {
      "displayName": "김흥중",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgvOxCHkryGVlZI4L_etMcHh1YeD6_ld365TwI47yU=s64",
      "userId": "04380006385771757274"
     },
     "user_tz": -540
    },
    "id": "4Y1bn1tZcGhi",
    "outputId": "9b05e6e6-872e-4f0b-ad7c-956c0fa4dda0"
   },
   "outputs": [],
   "source": [
    "# 열 지정하여 중복제거\n",
    "# 파라미터로 열을 지정해주면 지정된 열을 기준으로 중복을 제거해준다.\n",
    "\n",
    "# df.drop_duplicates(['Num'])\n",
    "df.drop_duplicates(['Num', 'Alphabet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1629260079207,
     "user": {
      "displayName": "김흥중",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgvOxCHkryGVlZI4L_etMcHh1YeD6_ld365TwI47yU=s64",
      "userId": "04380006385771757274"
     },
     "user_tz": -540
    },
    "id": "zCyIH0dycXVD",
    "outputId": "25f57fce-e672-48a6-a273-e9b9492a7c67"
   },
   "outputs": [],
   "source": [
    "# 남길 대상 지정\n",
    "# 첫 번째만 남기기\n",
    "df.drop_duplicates(['Num'], keep = 'first')\n",
    "\n",
    "# 마지막만 남기기\n",
    "# df.drop_duplicates(['Num'], keep = 'first')\n",
    "\n",
    "# 모두 제거\n",
    "# df.drop_duplicates(['Num'], keep = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "executionInfo": {
     "elapsed": 396,
     "status": "ok",
     "timestamp": 1629260133773,
     "user": {
      "displayName": "김흥중",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgvOxCHkryGVlZI4L_etMcHh1YeD6_ld365TwI47yU=s64",
      "userId": "04380006385771757274"
     },
     "user_tz": -540
    },
    "id": "HXCU3D_1dWpb",
    "outputId": "3aee12fb-9905-4d05-b7c7-aefdf2474fc2"
   },
   "outputs": [],
   "source": [
    "# 인덱스 재설정(Reset Index)\n",
    "\n",
    "df.drop_duplicates(['Num'], ignore_index = True)\n",
    "\n",
    "# 기존의 인덱스를 따랐기 때문에 중복을 제거한 후에는 사라진 행의 인덱스가 비게 된다.\n",
    "# 이때 ignore_index를 이용하면 인덱스를 재설정해줄 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhjQn76vno7X"
   },
   "source": [
    "## 파이썬으로 두 개의 엑셀 파일을 비교하기: excel diff\n",
    "엑셀로 데이터를 정리해서 관리하다 보면 종종 동일한 양식의 두 파일을 비교해야 할 때가 있습니다. 과거에 만들어 놓은 파일 A와 새로 업데이트한 파일 B를 비교하는 경우 말입니다. 이렇게 두 개의 파일을 비교할 때 확인하고 싶은 내용은 보통 세 가지 정도 일 것 같은데요.\n",
    "\n",
    "-. 새로 생긴 데이터\n",
    "-. 없어진 데이터\n",
    "-. 정보가 변경된 데이터 \n",
    "\n",
    "이런 작업을 파이썬 판다스 라이브러리를 사용해서 처리하는 방법을 다루려 합니다. 약간 난이도가 있어서 판다스 자체가 처음이시라면 조금 어려울지도 모르겠습니다.\n",
    "\n",
    "삭제된 데이터와 새로 추가된 데이터를 찾아내기 \n",
    "두 파일을 비교하기 위해서는, 두 파일 모두 동일한 컬럼 순서를 가지고 있고 개별 행 데이터를 구분할 수 있는 고유한 값을 지닌 컬럼이 존재해야 합니다. 예제 코드에서는 '아이디' 컬럼을 활용하겠습니다.\n",
    "\n",
    "- pandas 라이브러리를 불러옵니다.\n",
    "        import pandas as pd\n",
    "\n",
    "- 비교할 엑셀 파일들을 불러옵니다. \n",
    "        df_old = pd.read_excel('data_old.xlsx')\n",
    "        df_new = pd.read_excel('data_new.xlsx')\n",
    "\n",
    "- 어떤 파일이 예전에 만들어진 파일이고 어떤 파일이 새로운 파일인지 구분하기 위해 컬럼을 추가합니다.\n",
    "\n",
    "        df_old['ver'] = 'old'\n",
    "        df_new['ver'] = 'new'\n",
    " \n",
    "- set 함수를 이용하면 손쉽게 새로 추가된 데이터와 이전에 있었지만 삭제된 데이터를 발라낼 수 있습니다.\n",
    "\n",
    "        id_dropped = set(df_old['아이디']) - set(df_new['아이디'])\n",
    "        id_added = set(df_new['아이디']) - set(df_old['아이디'])\n",
    "        print('삭제된 아이템: ',id_dropped)\n",
    "        print('추가된 아이템: ',id_added)\n",
    "\n",
    "        df_dropped = df_old[df_old['아이디'].isin(id_dropped)].iloc[:,:-1]\n",
    "        df_added = df_new[df_new['아이디'].isin(id_added)].iloc[:,:-1]\n",
    "\n",
    "- 이전에 존재했다가 삭제된 데이터와 새로 추가된 데이터를 찾아내고, 그 결과를 새로운 데이터프레임으로 각각 만들었습니다.\n",
    "\n",
    "- 내용이 변경된 데이터 찾기 \n",
    "\n",
    "- 내용이 바뀐 데이터를 찾는 것은 조금 더 처리가 필요합니다. 주석을 천천히 읽어주세요.\n",
    "\n",
    "- 두 데이터프레임을 하나로 합칩니다.\n",
    "        df_concatted = pd.concat([df_old, df_new], ignore_index=True)\n",
    "- 모든 컬럼의 내용이 중복되는 데이터는 삭제합니다.\n",
    "        changes = df_concatted.drop_duplicates(df_concatted.columns[:-1], keep='last')\n",
    "\n",
    "- 남은 데이터 중 동일한 아이디 값이 두개 이상 존재한다면\n",
    "- 정보가 변경된 데이터입니다.\n",
    "        duplicated_list = changes[changes['아이디'].duplicated()]['아이디'].to_list()\n",
    "        df_changed = changes[changes['아이디'].isin(duplicated_list)]\n",
    "\n",
    "- 이렇게 처리된 데이터프레임은 위의 사진처럼 이전 데이터와 새롭게 업데이트된 데이터가 모두 들어있습니다. 다시 두 개의 데이터프레임으로 분리하겠습니다.\n",
    "\n",
    "        df_changed_old = df_changed[df_changed['ver'] == 'old'].iloc[:,:-1]\n",
    "        df_changed_old.sort_values(by='아이디', inplace=True)\n",
    "\n",
    "        df_changed_new = df_changed[df_changed['ver'] == 'new'].iloc[:,:-1]\n",
    "        df_changed_new.sort_values(by='아이디', inplace=True)\n",
    "\n",
    "- 반복문으로 두 데이터프레임 내 값을 차례대로 비교해서 그 결과를 정리하겠습니다.\n",
    "\n",
    "        df_info_changed = df_changed_old.copy()\n",
    "        for i in range(len(df_changed_new.index)):\n",
    "            for j in range(len(df_changed_new.columns)):\n",
    "                if (df_changed_new.iloc[i, j] != df_changed_old.iloc[i, j]):\n",
    "                   df_info_changed.iloc[i,j] = str(df_changed_old.iloc[i, j]) + \" ==> \" + str(df_changed_new.iloc[i,j])\n",
    "\n",
    "- 비교 결과를 엑셀로 저장하기 \n",
    "두 파일을 비교한 결과를 엑셀로 저장하겠습니다. 이 파일은 세 개의 시트로 구성됩니다. ①내용이 변경된 데이터, ②새롭게 추가된 데이터, ③기존에 있다가 삭제된 데이터\n",
    "\n",
    "        with pd.ExcelWriter('compared_result.xlsx') as writer:\n",
    "            df_info_changed.to_excel(writer, sheet_name='info changed', index=False)\n",
    "            df_added.to_excel(writer, sheet_name='added', index=False)\n",
    "            df_dropped.to_excel(writer, sheet_name='dropped', index=False)    \n",
    " \n",
    "- 엑셀 파일을 열어보면 아래와 같이 시트별로 잘 정리된 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yimycJIIpcxr"
   },
   "outputs": [],
   "source": [
    "# def compare_excel(old_xlsx, new_xlsx, column_name):\n",
    "    \n",
    "import pandas as pd    \n",
    "\n",
    "df_old = pd.read_excel('SupermarketSales.xlsx')\n",
    "df_new = pd.read_excel('SupermarketSalesNew.xlsx')\n",
    "\n",
    "# 불러온 데이터의 버전 구분\n",
    "df_old['ver'] = 'old'\n",
    "df_new['ver'] = 'new'\n",
    "\n",
    "id_dropped = set(df_old['거래번호']) - set(df_new['거래번호'])\n",
    "id_added = set(df_new['거래번호']) - set(df_old['거래번호'])\n",
    "\n",
    "# 삭제된 데이터\n",
    "df_dropped = df_old[df_old['거래번호'].isin(id_dropped)].iloc[:,:-1]\n",
    "# 추가된 데이터\n",
    "df_added = df_new[df_new['거래번호'].isin(id_added)].iloc[:,:-1]\n",
    "\n",
    "df_concatted = pd.concat([df_old, df_new], ignore_index=True)\n",
    "changes = df_concatted.drop_duplicates(df_concatted.columns[:-1], keep='last')\n",
    "duplicated_list = changes[changes['거래번호'].duplicated()]['거래번호'].to_list()\n",
    "df_changed = changes[changes['거래번호'].isin(duplicated_list)]\n",
    "\n",
    "df_changed_old = df_changed[df_changed['ver'] == 'old'].iloc[:,:-1]\n",
    "df_changed_old.sort_values(by='거래번호', inplace=True)\n",
    "\n",
    "df_changed_new = df_changed[df_changed['ver'] == 'new'].iloc[:,:-1]\n",
    "df_changed_new.sort_values(by='거래번호', inplace=True)\n",
    "\n",
    "# 정보가 변경된 데이터 정리\n",
    "df_info_changed = df_changed_old.copy()\n",
    "for i in range(len(df_changed_new.index)):\n",
    "    for j in range(len(df_changed_new.columns)):\n",
    "        if (df_changed_new.iloc[i, j] != df_changed_old.iloc[i, j]):\n",
    "            df_info_changed.iloc[i,j] = str(df_changed_old.iloc[i, j]) + \" ==> \" + str(df_changed_new.iloc[i,j])\n",
    "\n",
    "# 엑셀 저장            \n",
    "with pd.ExcelWriter('compared_result.xlsx') as writer:\n",
    "    df_info_changed.to_excel(writer, sheet_name='info changed', index=False)\n",
    "    df_added.to_excel(writer, sheet_name='added', index=False)\n",
    "    df_dropped.to_excel(writer, sheet_name='dropped', index=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAa5ofXdvpqK"
   },
   "source": [
    "## 여러 개의 엑셀 시트를 하나의 데이터프레임으로 결합하기: pd.read_excel()\n",
    "여러 개의 엑셀 시트를 하나의 데이터프레임으로 합치는 방법을 알아보겠습니다. \n",
    "\n",
    "샘플 데이터는 다음과 같이 생겼습니다. 온라인 소매 데이터로 세계 각국에서의 주문 기록이 담겨있습니다. 주문 국가에 따라 시트가 구분되어있으며 총 38개의 시트로 이루어졌습니다.\n",
    "\n",
    "- 샘플 데이터는 UCI Machine Learning Repository에서 제공하는 Online Retail Data Set를 수정하였습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zt6uhlnHv2mK"
   },
   "outputs": [],
   "source": [
    "# read_excel()\n",
    "# 판다스에는 엑셀을 읽어오기 위한 메서드 read_excel()이 존재합니다. 사용하는 방법은 매우 간단합니다. 매개변수로 파일의 이름을 넣어주면 끝납니다. (단, 스크립트와 같은 폴더에 위치한 파일이 아니라면 경로까지 넣어주셔야합니다.)\n",
    "\n",
    "import pandas as pd\n",
    "# excel_url = 'https://github.com/hogni-seoul/blog/raw/master/Online_Retail_Sample.xlsx'\n",
    "excel_url = 'Online_Retail_Sample.xlsx'\n",
    "df = pd.read_excel(excel_url)\n",
    "df\n",
    "\n",
    "# 별도의 다른 옵션을 설정하지 않는다면 가장 첫번째 시트를 데이터프레임으로 읽어옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fvok3fhRwyEM"
   },
   "outputs": [],
   "source": [
    "# 특정 시트를 읽어오기\n",
    "\n",
    "excel_url = 'https://github.com/hogni-seoul/blog/raw/master/Online_Retail_Sample.xlsx'\n",
    "# 첫번째 시트를 읽어옵니다.\n",
    "df1 = pd.read_excel(excel_url, sheet_name = 0)\n",
    "# 두번째 시트를 읽어옵니다.\n",
    "df2 = pd.read_excel(excel_url, sheet_name = 1)\n",
    "\n",
    "# 하나의 시트만을 읽어올 경우 바로 데이터프레임을 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nfL-N7xQxeX0"
   },
   "outputs": [],
   "source": [
    "# 모든 시트를 읽어오기\n",
    "\n",
    "excel_url = 'https://github.com/hogni-seoul/blog/raw/master/Online_Retail_Sample.xlsx'\n",
    "# 모든 시트를 읽어옵니다\n",
    "df_all = pd.read_excel(excel_url, sheet_name = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1629265310414,
     "user": {
      "displayName": "김흥중",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgvOxCHkryGVlZI4L_etMcHh1YeD6_ld365TwI47yU=s64",
      "userId": "04380006385771757274"
     },
     "user_tz": -540
    },
    "id": "IsD3R9qfxs6H",
    "outputId": "20d628b4-ad3b-4c96-c2d1-e7a497cb0008"
   },
   "outputs": [],
   "source": [
    "# 모든 시트를 읽어올 경우 collections.OrderedDict 객체를 반환합니다. key와 value 쌍으로 이루어져있으며, key 값을 이용해서 value 값을 얻어올 수 있습니다. 즉, 단일 데이터프레임 값을 가져올 수 있습니다.\n",
    "\n",
    "df_all.keys()\n",
    "# >>> odict_keys(['United Kingdom', 'France', ..., 'RSA'])\n",
    "df_all['France']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "executionInfo": {
     "elapsed": 383,
     "status": "ok",
     "timestamp": 1629265322699,
     "user": {
      "displayName": "김흥중",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgvOxCHkryGVlZI4L_etMcHh1YeD6_ld365TwI47yU=s64",
      "userId": "04380006385771757274"
     },
     "user_tz": -540
    },
    "id": "LHfyaY26x27B",
    "outputId": "b98535ea-23e0-489e-e291-cf3fb07fdf89"
   },
   "outputs": [],
   "source": [
    "# 모든 데이터프레임을 하나로 합치기 위해서는 concat() 메서를 사용하면됩니다. 인덱스는 필요 없으므로 무시하겠습니다. 결합된 데이터프레임을 반환합니다.\n",
    "\n",
    "concatted_df = pd.concat(df_all, ignore_index=True)\n",
    "concatted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fCY-shUyyUgT"
   },
   "outputs": [],
   "source": [
    "# 결합된 데이터를 엑셀로 저장\n",
    "concatted_df.to_excel('Online_Retail_Sample.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dErvgU3L4Czy"
   },
   "source": [
    "##pandas 데이터프레임을 엑셀로 저장하기, 둘 이상의 엑셀 시트로 저장하기: to_excel(), pd.ExcelWriter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "executionInfo": {
     "elapsed": 420,
     "status": "ok",
     "timestamp": 1629266991710,
     "user": {
      "displayName": "김흥중",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgvOxCHkryGVlZI4L_etMcHh1YeD6_ld365TwI47yU=s64",
      "userId": "04380006385771757274"
     },
     "user_tz": -540
    },
    "id": "AcvTpQOr4Nfi",
    "outputId": "14b9c8f3-dda5-4e01-dc3f-6796aa91bba9"
   },
   "outputs": [],
   "source": [
    "# 판다스 데이터프레임을 엑셀 형태로 저장하기 위해서는 to_excel() 메서드를 사용하면 됩니다. 이때 메서드의 매개 변수로 저장할 파일의 이름을 전달합니다. \n",
    "# 경로를 별도 지정하지 않는다면 현재 스크립트가 위치한 폴더에 엑셀 파일이 생성됩니다. 샘플 데이터를 보겠습니다.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 샘플 데이터프레임 생성\n",
    "inventors = pd.DataFrame(\n",
    "    {\n",
    "        'name': ['Nikola Tesla', 'Thomas Edison', 'Henry Ford'],\n",
    "        'born': ['1856/07/10', '1847/02/11', '1863/07/30'],\n",
    "        'died': ['1943/01/07', '1931/10/18', '1947/04/07'],\n",
    "        'age': [86, 84, 83]\n",
    "})\n",
    "\n",
    "# 결과 출력\n",
    "inventors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VK8i9FZy4VZ5"
   },
   "outputs": [],
   "source": [
    "# to_excel()를 사용해서 엑셀로 저장하기\n",
    "# 매개 변수로 저장할 파일 이름을 전달합니다.\n",
    "\n",
    "inventors.to_excel('inventors.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ko2G0rC54g80"
   },
   "outputs": [],
   "source": [
    "# 인덱스 없이 저장하는 것도 가능합니다.\n",
    "\n",
    "# 이제 인덱스는 저장되지 않습니다.\n",
    "inventors.to_excel('inventors.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nzwatBGw4ujE"
   },
   "outputs": [],
   "source": [
    "# pd.ExcelWriter()를 사용해서 둘 이상의 엑셀 시트로 저장하기\n",
    "with pd.ExcelWriter('inventors.xlsx') as writer:\n",
    "    inventors[inventors.name == 'Nikola Tesla'].to_excel(writer, sheet_name='Nikola Tesla')\n",
    "    inventors[inventors.name == 'Thomas Edison'].to_excel(writer, sheet_name='Thomas Edison')\n",
    "    inventors[inventors.name == 'Henry Ford'].to_excel(writer, sheet_name='Henry Ford')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AXeDn8B05Plp"
   },
   "outputs": [],
   "source": [
    "# 이름에 따라 개별 시트에 저장된 것을 볼 수 있습니다. 아래 코드처럼 조금 더 간단히 작성할 수도 있습니다.\n",
    "\n",
    "with pd.ExcelWriter('inventors.xlsx') as writer:\n",
    "    for name in inventors.name:\n",
    "        inventors[inventors.name == f'{name}'].to_excel(writer, sheet_name=f'{name}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "_PandasXL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
